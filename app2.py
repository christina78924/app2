import streamlit as st
import pandas as pd
import numpy as np
import re
import io
import os

# --- è¨­å®šç¶²é æ¨™é¡Œ ---
st.set_page_config(page_title="IPQC CPK & Yield è‡ªå‹•ç”Ÿæˆå™¨", layout="wide")
st.title("ğŸ“Š IPQC CPK & Yield å ±è¡¨ç”Ÿæˆå™¨")
st.markdown("è‡ªå‹•æƒæ Excelï¼Œä¸¦ä¾ç…§æŒ‡å®šé †åºè¼¸å‡º 19 å€‹ç«™é»çš„è‰¯ç‡èˆ‡ CPK å ±è¡¨ã€‚")

# --- 1. å®šç¾© 19 å€‹ç«™é»çš„æ¨™æº–é †åº ---
TARGET_ORDER = [
    "MLA assy installation",
    "Mirror attachment",
    "Barrel attachment",
    "Condenser lens attach",
    "LED Module  attachment",
    "ILLU Module cover attachment",
    "Relay lens attachment",
    "LED FLEX GRAPHITE-1",
    "reflector attach",
    "singlet attach",
    "HWP Mylar attach",
    "PBS attachment",
    "Doublet attachment",
    "Top cover installation",
    "PANEL PRECISION AAï¼ˆLAAï¼‰",
    "POST DAA INSPECTION",
    "PANEL FLEX ASSY",
    "LCOS GRAPHITE ATTACH",
    "DE OQC"
]

# --- 2. è¼”åŠ©å‡½å¼ï¼šåç¨±æ­£è¦åŒ– ---
def normalize_name(name):
    """ç§»é™¤ç©ºæ ¼ã€æ‹¬è™Ÿã€ç‰¹æ®Šç¬¦è™Ÿä¸¦è½‰å°å¯«ï¼Œç”¨æ–¼æ¨¡ç³Šæ¯”å°"""
    return name.lower().replace(" ", "").replace("ã€€", "").replace("(", "").replace(")", "").replace("ï¼ˆ", "").replace("ï¼‰", "").replace("-", "").replace("_", "")

# å»ºç«‹å°ç…§è¡¨
TARGET_MAP = {}
for name in TARGET_ORDER:
    key = normalize_name(name)
    TARGET_MAP[key] = name

# --- 3. æ ¸å¿ƒè¨ˆç®—å‡½å¼ (CPK) ---
def calculate_cpk_value(data, usl, lsl):
    try:
        clean_data = pd.to_numeric(data, errors='coerce').dropna()
        if len(clean_data) < 2: return np.nan
        
        mean = np.mean(clean_data)
        std = np.std(clean_data, ddof=1)
        if std == 0: return np.nan
        
        cpu = np.nan
        cpl = np.nan
        has_usl = False
        has_lsl = False
        
        if not pd.isna(usl):
            cpu = (usl - mean) / (3 * std)
            has_usl = True
        if not pd.isna(lsl):
            cpl = (mean - lsl) / (3 * std)
            has_lsl = True
            
        if has_usl and has_lsl: return min(cpu, cpl)
        elif has_usl: return cpu
        elif has_lsl: return cpl
        else: return np.nan
    except:
        return np.nan

# --- 4. å°‹æ‰¾ Header åˆ—ç´¢å¼• ---
def find_header_row(df, keywords):
    for i in range(min(60, len(df))):
        row_str = " ".join(df.iloc[i].astype(str).fillna("").str.lower())
        for kw in keywords:
            if kw in row_str:
                return i
    return -1

# --- 5. è™•ç†å–®ä¸€ Sheet (Yield) ---
def process_yield(station_display_name, df):
    best_col = -1
    max_count = 0
    cols_to_scan = min(df.shape[1], 30)
    
    for c in range(cols_to_scan):
        col_data = df.iloc[:, c].astype(str).str.upper()
        ok_count = (col_data == "OK").sum()
        ng_count = (col_data == "NG").sum()
        total = ok_count + ng_count
        
        if total > max_count:
            max_count = total
            best_col = c
            
    if best_col != -1 and max_count > 0:
        col_data = df.iloc[:, best_col].astype(str).str.upper()
        ok_qty = (col_data == "OK").sum()
        ng_qty = (col_data == "NG").sum()
        total_qty = ok_qty + ng_qty
        yield_rate = ok_qty / total_qty if total_qty > 0 else 0
        
        return {
            "Station": station_display_name,
            "Total Qty": total_qty,
            "OK Qty": ok_qty,
            "NG Qty": ng_qty,
            "Yield": yield_rate
        }
    return None

# --- 6. è™•ç†å–®ä¸€ Sheet (CPK) ---
def process_cpk(station_display_name, df):
    # 1. å®šä½æ¨™é¡Œåˆ—
    dim_row_idx = find_header_row(df, ["dim. no", "dim no", "dim.no"])
    usl_row_idx = find_header_row(df, ["usl"])
    lsl_row_idx = find_header_row(df, ["lsl"])
    
    # å˜—è©¦å®šä½ Config ç›¸é—œæ¨™é¡Œåˆ— (è‹¥ Dim No åŒåˆ—å‰‡ç„¡éœ€é¡å¤–å®šä½)
    # é€™è£¡å‡è¨­ Config å¯èƒ½åœ¨ Dim No åŒä¸€åˆ—ï¼Œæˆ–è€…å‰ 10 åˆ—çš„ metadata å€åŸŸ
    config_col_idx = -1
    
    if dim_row_idx == -1: return []

    # 2. è§£ææ¬„ä½ (Dim No) å’Œå°‹æ‰¾ Config æ¬„ä½
    headers = df.iloc[dim_row_idx].astype(str).fillna("").tolist()
    dim_cols = {}
    
    # é—œéµå­—é»‘åå–®
    ignore_list = ["date", "time", "no.", "remark", "judge", "note", "supplier", "station", "model", "lot", "cavity", "nan", "", "config", "configuration", "type"]
    
    for idx, name in enumerate(headers):
        clean_name = name.strip()
        lower_name = clean_name.lower()
        
        # åµæ¸¬ Config æ¬„ä½ (å¦‚æœè¡¨é ­æœ‰ 'config', 'model', 'type' ç­‰å­—çœ¼)
        if config_col_idx == -1 and any(k in lower_name for k in ["config", "model", "type", "description"]):
             config_col_idx = idx
        
        if len(clean_name) > 1 and lower_name not in ignore_list:
            dim_cols[idx] = clean_name

    # 3. å–å¾—è¦æ ¼é™ (USL/LSL)
    usls = {}
    lsls = {}
    
    if usl_row_idx != -1:
        row_vals = df.iloc[usl_row_idx].tolist()
        for idx, val in enumerate(row_vals):
            try: usls[idx] = float(val)
            except: pass
            
    if lsl_row_idx != -1:
        row_vals = df.iloc[lsl_row_idx].tolist()
        for idx, val in enumerate(row_vals):
            try: lsls[idx] = float(val)
            except: pass

    # 4. æå–æ•¸æ“šä¸¦è¨ˆç®—
    results = []
    start_row = max(dim_row_idx, usl_row_idx, lsl_row_idx) + 1
    
    # æå–éœ€è¦çš„è³‡æ–™å€å¡Š
    data_block = df.iloc[start_row:].copy()
    
    # å°‹æ‰¾æ—¥æœŸæ¬„ä½ (å‡è¨­åœ¨å‰ 15 æ¬„å…§)
    date_col_idx = -1
    for c in range(min(15, data_block.shape[1])):
        sample = data_block.iloc[:, c].astype(str)
        if sample.str.contains(r'202\d-\d{2}-\d{2}', regex=True).any():
            date_col_idx = c
            break
            
    if date_col_idx != -1:
        # çµ±ä¸€æ—¥æœŸæ ¼å¼
        data_block['Date_Clean'] = data_block.iloc[:, date_col_idx].astype(str).str.extract(r'(202\d-\d{2}-\d{2})')[0]
        data_block = data_block.dropna(subset=['Date_Clean'])
        
        # è™•ç† Config å€¼
        # å¦‚æœæœ‰æ‰¾åˆ° Config æ¬„ä½ï¼Œå°±å–å€¼ï¼›å¦å‰‡è¨­ç‚ºç©ºå­—ä¸²æˆ–é è¨­å€¼
        if config_col_idx != -1:
            data_block['Config_Val'] = data_block.iloc[:, config_col_idx].astype(str).replace('nan', '')
        else:
            data_block['Config_Val'] = "" # é è¨­ç‚ºç©ºï¼Œè‹¥éœ€è¦é è¨­å€¼å¯æ”¹é€™è£¡ï¼Œå¦‚ "Default"

        grouped = data_block.groupby(['Date_Clean', 'Config_Val'])
        
        for (date, config_val), group in grouped:
            for col_idx, dim_name in dim_cols.items():
                vals = group.iloc[:, col_idx]
                
                u = usls.get(col_idx, np.nan)
                l = lsls.get(col_idx, np.nan)
                
                cpk = calculate_cpk_value(vals, u, l)
                
                clean_vals = pd.to_numeric(vals, errors='coerce').dropna()
                sample_size = len(clean_vals)
                
                if sample_size > 0:
                    results.append({
                        "Station": station_display_name,
                        "Dim No": dim_name,
                        "config": config_val,  # æ–°å¢ config æ¬„ä½
                        "Date": date,
                        "Sample Size": sample_size,
                        "USL": u if not pd.isna(u) else "",
                        "LSL": l if not pd.isna(l) else "",
                        "CPK": round(cpk, 3) if not pd.isna(cpk) else ""
                    })
                    
    return results

# --- ä¸»ç¨‹å¼ä»‹é¢ ---

uploaded_file = st.file_uploader("ğŸ“‚ è«‹ä¸Šå‚³ Excel æª”æ¡ˆ (.xlsx)", type=["xlsx"])

if uploaded_file is not None:
    st.info("æ­£åœ¨è®€å–ä¸¦åˆ†ææ‰€æœ‰åˆ†é ï¼Œè«‹ç¨å€™...")
    
    try:
        xls = pd.ExcelFile(uploaded_file)
        all_sheet_names = xls.sheet_names
        
        yield_list = []
        cpk_list = []
        
        progress_bar = st.progress(0)
        
        for i, sheet_name in enumerate(all_sheet_names):
            norm_sheet = normalize_name(sheet_name)
            
            display_name = None
            for key, val in TARGET_MAP.items():
                if key in norm_sheet or norm_sheet in key:
                    display_name = val
                    break
            
            # ç‰¹æ®Šä¿®æ­£
            if "postdaa" in norm_sheet: display_name = "POST DAA INSPECTION"
            if "ledmoduleattachment" in norm_sheet: display_name = "LED Module  attachment"
            
            if not display_name or any(x in norm_sheet for x in ["summary", "slice", "template", "inline", "history"]):
                continue

            df = pd.read_excel(uploaded_file, sheet_name=sheet_name, header=None)
            
            y_res = process_yield(display_name, df)
            if y_res: yield_list.append(y_res)
            
            c_res = process_cpk(display_name, df)
            if c_res: cpk_list.extend(c_res)
            
            progress_bar.progress((i + 1) / len(all_sheet_names))

        # --- æ•´ç†èˆ‡æ’åº (Yield) ---
        df_yield = pd.DataFrame(yield_list)
        if not df_yield.empty:
            df_yield['Station'] = pd.Categorical(df_yield['Station'], categories=TARGET_ORDER, ordered=True)
            df_yield = df_yield.sort_values('Station')
            df_yield["Yield"] = df_yield["Yield"].apply(lambda x: f"{x*100:.2f}%")

        # --- æ•´ç†èˆ‡æ’åº (CPK) ---
        df_cpk = pd.DataFrame(cpk_list)
        if not df_cpk.empty:
            df_cpk['Station'] = pd.Categorical(df_cpk['Station'], categories=TARGET_ORDER, ordered=True)
            
            # æŒ‡å®šæ¬„ä½é †åºï¼šåŠ å…¥ config
            cols = ["Station", "Dim No", "config", "Date", "Sample Size", "USL", "LSL", "CPK"]
            df_cpk = df_cpk[cols]
            
            df_cpk = df_cpk.sort_values(by=['Station', 'Dim No', 'Date'])

        st.success("âœ… è¨ˆç®—å®Œæˆï¼")
        
        tab1, tab2 = st.tabs(["è‰¯ç‡ç¸½è¡¨ (Yield)", "CPK è©³ç´°å ±è¡¨ (å« Config)"])
        
        with tab1:
            st.dataframe(df_yield, use_container_width=True)
            
        with tab2:
            st.dataframe(df_cpk, use_container_width=True)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            if not df_yield.empty:
                df_yield.to_excel(writer, sheet_name='Yield Summary', index=False)
            if not df_cpk.empty:
                df_cpk.to_excel(writer, sheet_name='CPK Detail', index=False)
                
        output.seek(0)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´ Excel å ±è¡¨",
            data=output,
            file_name="IPQC_Report.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        
    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")